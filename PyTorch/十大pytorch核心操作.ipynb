{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "参考：https://mp.weixin.qq.com/s/hhhWrJMnrHsRGuwYG2XQVw\n",
    "\n",
    "---\n",
    "\n",
    "# 张量的创建和基本操作\n",
    "\n",
    "张量类似于 NumPy 的数组，但具有额外的功能，如自动求导（automatic differentiation）和 GPU 加速。\n",
    "\n",
    "下面是在 PyTorch 中创建张量和进行基本操作的详细介绍。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4231c41351e7016c"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "17761028a8a03398"
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## 1. 张量的创建\n",
    "从 Python 列表或 Numpy 数组创建张量"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "16d4942d984ba403"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor_from_list: tensor([1, 2, 3])\n",
      "tensor_from_numpy: tensor([4, 5, 6], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# 从列表创建张量\n",
    "tensor_from_list = torch.tensor([1, 2, 3])\n",
    "print(\"tensor_from_list:\", tensor_from_list)\n",
    "\n",
    "# 从 NumPy 数组创建张量\n",
    "numpy_array = np.array([4, 5, 6])\n",
    "tensor_from_numpy = torch.tensor(numpy_array)\n",
    "print(\"tensor_from_numpy:\", tensor_from_numpy)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T06:47:10.081267300Z",
     "start_time": "2024-01-15T06:47:08.585913400Z"
    }
   },
   "id": "a7a649bd6e76b0a7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "使用特定值创建张量"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ec4aa6f49d4155a1"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zeros_tensor:\n",
      " tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "ones_tensor:\n",
      " tensor([[1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.]])\n",
      "range_tensor:\n",
      " tensor([0, 2, 4, 6, 8])\n",
      "uniform_tensor:\n",
      " tensor([[0.8852, 0.9501, 0.7682],\n",
      "        [0.9928, 0.8854, 0.7121],\n",
      "        [0.4901, 0.3520, 0.6206]])\n",
      "normal_tensor:\n",
      " tensor([[ 0.1165, -1.5052],\n",
      "        [ 0.4699,  0.6822]])\n"
     ]
    }
   ],
   "source": [
    "# 创建全零张量\n",
    "zeros_tensor = torch.zeros((3, 4))\n",
    "print(\"zeros_tensor:\\n\", zeros_tensor)\n",
    "\n",
    "# 创建全一张量\n",
    "ones_tensor = torch.ones((4, 2))\n",
    "print(\"ones_tensor:\\n\", ones_tensor)\n",
    "\n",
    "# 创建指定范围的张量\n",
    "range_tensor = torch.arange(0, 10, 2)\n",
    "print(\"range_tensor:\\n\", range_tensor)\n",
    "\n",
    "# 创建均匀分布的张量\n",
    "uniform_tensor = torch.rand((3, 3))\n",
    "print(\"uniform_tensor:\\n\", uniform_tensor)\n",
    "\n",
    "# 创建正态分布的张量\n",
    "normal_tensor = torch.randn((2, 2))\n",
    "print(\"normal_tensor:\\n\", normal_tensor)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T06:47:10.082267900Z",
     "start_time": "2024-01-15T06:47:09.229877400Z"
    }
   },
   "id": "c042fd1baae2289b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "使用特定形状的张量"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9b2cc1b71d58c011"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uninitialized_tensor:\n",
      " tensor([[8.9082e-39, 8.4490e-39],\n",
      "        [9.2755e-39, 1.0286e-38]])\n",
      "like_tensor:\n",
      " tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# 创建未初始化的张量\n",
    "uninitialized_tensor = torch.empty((2, 2))\n",
    "print(\"uninitialized_tensor:\\n\", uninitialized_tensor)\n",
    "\n",
    "# 创建与现有张量相同形状的张量\n",
    "like_tensor = torch.ones_like(zeros_tensor)\n",
    "print(\"like_tensor:\\n\", like_tensor)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T06:47:10.082267900Z",
     "start_time": "2024-01-15T06:47:09.244877500Z"
    }
   },
   "id": "47991833dba45344"
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## 2. 张量的基本操作\n",
    "\n",
    "索引和切片："
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "47a081c661d22b07"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "element: tensor(2)\n",
      "sliced_tensor: tensor([2, 3])\n"
     ]
    }
   ],
   "source": [
    "# 获取张量中的特定元素\n",
    "element = tensor_from_list[1]\n",
    "print(\"element:\", element)\n",
    "\n",
    "# 切片操作\n",
    "sliced_tensor = tensor_from_list[1:3]\n",
    "print(\"sliced_tensor:\", sliced_tensor)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T06:47:10.082267900Z",
     "start_time": "2024-01-15T06:47:09.261877400Z"
    }
   },
   "id": "7472d48a9d23b19b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "张量的形状操作"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f4f38db804751d93"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: torch.Size([3])\n",
      "reshaped_tensor: tensor([[1, 2, 3]])\n",
      "transposed_tensor: tensor([1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "# 获取张量的形状\n",
    "shape = tensor_from_list.shape\n",
    "print(\"shape:\", shape)\n",
    "\n",
    "# 改变张量的形状\n",
    "reshaped_tensor = tensor_from_list.view(1, 3)\n",
    "print(\"reshaped_tensor:\", reshaped_tensor)\n",
    "\n",
    "# 转置张量\n",
    "transposed_tensor = tensor_from_list.t()\n",
    "print(\"transposed_tensor:\", transposed_tensor)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T06:47:10.082267900Z",
     "start_time": "2024-01-15T06:47:09.277762200Z"
    }
   },
   "id": "878da61b083cd86b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "数学运算"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ab1d0e8629e7d2c4"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum_tensor: tensor([5, 7, 9])\n",
      "product_tensor:\n",
      " tensor([[0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.]])\n",
      "broadcasted_tensor: tensor([2, 4, 6])\n"
     ]
    }
   ],
   "source": [
    "# 加法\n",
    "sum_tensor = tensor_from_list + tensor_from_numpy\n",
    "print(\"sum_tensor:\", sum_tensor)\n",
    "\n",
    "# 乘法\n",
    "product_tensor = torch.matmul(zeros_tensor, ones_tensor)\n",
    "print(\"product_tensor:\\n\", product_tensor)\n",
    "\n",
    "# 广播操作\n",
    "broadcasted_tensor = tensor_from_list * 2\n",
    "print(\"broadcasted_tensor:\", broadcasted_tensor)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T06:47:10.082267900Z",
     "start_time": "2024-01-15T06:47:09.293682800Z"
    }
   },
   "id": "2a1d8328635c3e5e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 自动求导\n",
    "PyTorch中的自动求导（Autograd）允许用户自动计算张量的梯度，而无需手动编写反向传播算法。\n",
    "Autograd的核心是计算图（computational graph），它记录了计算张量的操作，并在需要时能够生成梯度。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7752bdc343938649"
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## 1. 张量的requires_grad属性\n",
    "在创建张量时，可以通过设置 `requires_grad` 属性为True来指示PyTorch跟踪对该张量的操作，从而构建计算图。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7687c56949a16fb"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 创建一个需要梯度的张量\n",
    "x = torch.tensor([1.0, 2.0], requires_grad=True)\n",
    "print(x)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T06:47:10.082267900Z",
     "start_time": "2024-01-15T06:47:09.309682400Z"
    }
   },
   "id": "a29a661bf79217bb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## 2. 张量操作和计算图\n",
    "一旦设置了 `requires_grad=True`，PyTorch 将自动追踪对该张量的所有操作，构建一个计算图。这个计算图记录了张量之间的关系和操作。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a37193024f2a5063"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y: tensor([3., 4.], grad_fn=<AddBackward0>)\n",
      "z: tensor([27., 48.], grad_fn=<MulBackward0>)\n",
      "out: tensor(37.5000, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y = x + 2\n",
    "z = y * y * 3\n",
    "out = z.mean()\n",
    "\n",
    "print(\"y:\", y)\n",
    "print(\"z:\", z)\n",
    "print(\"out:\", out)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T06:47:10.082267900Z",
     "start_time": "2024-01-15T06:47:09.325682800Z"
    }
   },
   "id": "6d00ee5227d3254a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "上述例子中，`y`、`z` 和 `out` 都是通过对 `x` 进行操作得到的新张量，这些操作构成了计算图。\n",
    "\n",
    "---\n",
    "\n",
    "## 3. 计算梯度\n",
    "一旦有了计算图，可以调用 `backward()` 方法计算梯度。梯度计算完成后，可以通过张量的 `grad` 属性获取梯度值。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ce7b13ccdc2fbf96"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 9., 12.])\n"
     ]
    }
   ],
   "source": [
    "out.backward()  # 计算梯度\n",
    "\n",
    "# 获取梯度\n",
    "print(x.grad)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T06:47:10.083305300Z",
     "start_time": "2024-01-15T06:47:09.341682300Z"
    }
   },
   "id": "54b246ba25e6ae19"
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## 4. 阻止梯度追踪\n",
    "在某些情况下，可能需要阻止 PyTorch 对某些操作的梯度追踪，可以使用 `torch.no_grad()` 上下文管理器或者在张量上使用 `.detach()` 方法。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7472fe153f4287d"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y: tensor([3., 4.])\n",
      "z: tensor([3., 4.])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    # 不追踪梯度的操作\n",
    "    y = x + 2\n",
    "\n",
    "# 或者\n",
    "z = y.detach()\n",
    "print(\"y:\", y)\n",
    "print(\"z:\", z)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T06:47:10.083305300Z",
     "start_time": "2024-01-15T06:47:09.373682600Z"
    }
   },
   "id": "e4b45a93e8edfd91"
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## 5. 使用 `with torch.autograd.set_grad_enabled(False):` 控制梯度计算\n",
    "在某些情况下，可能需要在一段代码中关闭梯度计算，可以使用上下文管理器 `torch.autograd.set_grad_enabled`。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9a33fb03ef363120"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y: tensor([3., 4.])\n"
     ]
    }
   ],
   "source": [
    "with torch.autograd.set_grad_enabled(False):\n",
    "    # 在此处的操作不会被追踪，也不会计算梯度\n",
    "    y = x + 2\n",
    "print(\"y:\", y)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T06:47:10.083305300Z",
     "start_time": "2024-01-15T06:47:09.388682200Z"
    }
   },
   "id": "85937121d230478b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## 6. 示例：使用自动求导进行优化"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8def5d05cbfef62"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-2.0713,  0.6335], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# 定义一个变量并设置需要梯度\n",
    "x = torch.tensor([1.0, 2.0], requires_grad=True)\n",
    "\n",
    "# 定义一个优化器（例如梯度下降）\n",
    "optimizer = optim.SGD([x], lr=0.01)\n",
    "\n",
    "# 在循环中执行优化步骤\n",
    "for _ in range(100):\n",
    "    y = x + 2\n",
    "    loss = y[0] * y[1]  # 这里定义了一个简单的损失函数\n",
    "\n",
    "    optimizer.zero_grad()  # 清零梯度\n",
    "    loss.backward()  # 计算梯度\n",
    "    optimizer.step()  # 更新参数\n",
    "\n",
    "# 查看优化后的结果\n",
    "print(x)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T06:47:10.083305300Z",
     "start_time": "2024-01-15T06:47:09.405720800Z"
    }
   },
   "id": "64dc243d0f06c098"
  },
  {
   "cell_type": "markdown",
   "source": [
    "这个例子演示了如何使用自动求导来执行优化步骤，通过反向传播计算梯度并使用优化器更新参数。\n",
    "\n",
    "总体而言，PyTorch中的自动求导提供了一个方便的工具，使得深度学习的模型训练变得更加简单和高效。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e0dfa17a340a78c1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 神经网络层\n",
    "\n",
    "在 PyTorch 中，`nn.Module` 是构建神经网络模型的基础类。`nn.Module` 提供了一个模块化和灵活的方式来组织复杂的神经网络结构。通过继承 `nn.Module` 类，可以创建自定义的神经网络层、模型或整个神经网络。\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8791bdfa1aa52cf4"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e76c60d070e644d0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## 1. 创建一个简单的神经网络层"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1f161fe03e54ab3a"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class SimpleLayer(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(SimpleLayer, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        x = self.relu(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T06:47:10.083305300Z",
     "start_time": "2024-01-15T06:47:09.420682200Z"
    }
   },
   "id": "8231cf4672188c25"
  },
  {
   "cell_type": "markdown",
   "source": [
    "上面的例子中，`SimpleLayer` 继承自 `nn.Module`，并定义了一个包含线性层（`nn.Linear`）和激活函数 ReLU 的简单神经网络层。`forward` 方法定义了前向传播的计算过程。\n",
    "\n",
    "---\n",
    "\n",
    "### 2. 构建更复杂的模型\n",
    "可以通过将多个神经网络层组合在一起构建更复杂的模型。下面是一个简单的多层感知机 (MLP) 的例子："
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9679314ccc9ab720"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.layer1 = SimpleLayer(input_size, hidden_size)\n",
    "        self.layer2 = SimpleLayer(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T06:47:10.083305300Z",
     "start_time": "2024-01-15T06:47:09.438682700Z"
    }
   },
   "id": "324e6411793076bb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## 3. 模块的嵌套和子模块\n",
    "`nn.Module` 支持嵌套和包含其他 `nn.Module` 实例，这有助于构建更复杂的神经网络。子模块会自动跟踪其参数和梯度。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7637f778d8402014"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "class ComplexModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ComplexModel, self).__init__()\n",
    "        self.layer1 = SimpleLayer(10, 20)\n",
    "        self.layer2 = MLP(20, 30, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T06:47:10.083305300Z",
     "start_time": "2024-01-15T06:47:09.453892700Z"
    }
   },
   "id": "f81c1915e379ffad"
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## 4. 访问模块的参数\n",
    "通过 `named_parameters()` 或 `parameters()` 方法可以访问模块中的所有参数。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dfe948c91806db18"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer1.linear.weight: torch.Size([20, 10])\n",
      "layer1.linear.bias: torch.Size([20])\n",
      "layer2.layer1.linear.weight: torch.Size([30, 20])\n",
      "layer2.layer1.linear.bias: torch.Size([30])\n",
      "layer2.layer2.linear.weight: torch.Size([5, 30])\n",
      "layer2.layer2.linear.bias: torch.Size([5])\n"
     ]
    }
   ],
   "source": [
    "model = ComplexModel()\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name}: {param.size()}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T06:47:10.083305300Z",
     "start_time": "2024-01-15T06:47:09.468565500Z"
    }
   },
   "id": "b0253aad870ad73b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## 5. 模型的保存和加载\n",
    "可以使用 `torch.save` 保存模型的状态字典，并使用 `torch.load` 加载模型。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a2363f8252a33c47"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 保存模型\n",
    "torch.save(model.state_dict(), 'model.pth')\n",
    "\n",
    "# 加载模型\n",
    "loaded_model = ComplexModel()\n",
    "loaded_model.load_state_dict(torch.load('model.pth'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T06:47:10.084267800Z",
     "start_time": "2024-01-15T06:47:09.484565400Z"
    }
   },
   "id": "beb808c43bc00d28"
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## 6. 模型的设备移动\n",
    "可以使用 `to` 方法将模型移动到指定的设备，例如 GPU。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2c3d84ca21090a74"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "ComplexModel(\n  (layer1): SimpleLayer(\n    (linear): Linear(in_features=10, out_features=20, bias=True)\n    (relu): ReLU()\n  )\n  (layer2): MLP(\n    (layer1): SimpleLayer(\n      (linear): Linear(in_features=20, out_features=30, bias=True)\n      (relu): ReLU()\n    )\n    (layer2): SimpleLayer(\n      (linear): Linear(in_features=30, out_features=5, bias=True)\n      (relu): ReLU()\n    )\n  )\n)"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T06:47:10.084267800Z",
     "start_time": "2024-01-15T06:47:09.500565Z"
    }
   },
   "id": "f73721514e4cc94"
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## 7. 自定义层和操作\n",
    "可以通过继承 `nn.Module` 类创建自定义的神经网络层和操作，例如自定义的激活函数、损失函数等。\n",
    "\n",
    "这些功能使得 `nn.Module` 成为 PyTorch 中构建和组织神经网络的核心工具之一。通过模块化的设计，可以更灵活地搭建、训练和调整复杂的神经网络结构。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6066959cb1a4673a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 优化器\n",
    "\n",
    "在 PyTorch 中，优化器（Optimizer）是用于更新神经网络模型参数的工具。优化器基于模型参数的梯度信息来调整参数，从而最小化或最大化某个损失函数。PyTorch 提供了多种优化器，包括随机梯度下降（SGD）、Adam、RMSprop 等。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1485a2791fe8561d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "## 1. SGD优化器\n",
    "\n",
    "随机梯度下降是最基本的优化算法之一。在 PyTorch 中，可以使用 `torch.optim.SGD` 类来创建 SGD 优化器"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2f92d6e636026d0f"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "# 定义模型和损失函数\n",
    "model = ComplexModel()\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# 定义 SGD 优化器\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T06:47:10.084267800Z",
     "start_time": "2024-01-15T06:47:09.581318600Z"
    }
   },
   "id": "e4f3c275e08a797e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## 2. Adam 优化器\n",
    "Adam 是一种自适应学习率的优化算法，它在训练深度学习模型时表现良好。在 PyTorch 中，可以使用 `torch.optim.Adam` 类来创建 Adam 优化器。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "14a6013e2039cc56"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# 定义 Adam 优化器\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T06:47:10.084267800Z",
     "start_time": "2024-01-15T06:47:09.597268200Z"
    }
   },
   "id": "cde580dc8ab35da4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## 3. RMSprop 优化器\n",
    "RMSprop（Root Mean Square Propagation）是另一种自适应学习率的优化算法。在 PyTorch 中，可以使用 `torch.optim.RMSprop` 类来创建 RMSprop 优化器。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d484fed313f92074"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "# 定义 RMSprop 优化器\n",
    "optimizer = optim.RMSprop(model.parameters(), lr=0.001)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T06:47:10.084267800Z",
     "start_time": "2024-01-15T06:47:09.613351200Z"
    }
   },
   "id": "1faeaae51aa5dd83"
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## 4. 设置学习率\n",
    "可以通过 `lr` 参数来设置优化器的学习率。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d71463f7be933340"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T06:47:10.084267800Z",
     "start_time": "2024-01-15T06:47:09.628358500Z"
    }
   },
   "id": "2ec70d56fc16ec06"
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## 5. 梯度清零\n",
    "在每个训练步骤之前，通常需要清零梯度。可以使用 `zero_grad()` 方法来实现。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "75bf8df08cdc8026"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "optimizer.zero_grad()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T06:47:10.084267800Z",
     "start_time": "2024-01-15T06:47:09.644345400Z"
    }
   },
   "id": "786175cefd2a508e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## 6. 梯度更新\n",
    "使用优化器的 `step()` 方法来更新模型参数。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c820893a468e0d45"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6931, grad_fn=<DivBackward1>)\n"
     ]
    }
   ],
   "source": [
    "y_true = torch.tensor([0, 1], dtype=torch.float32, requires_grad=True)\n",
    "y_pred = torch.tensor([1, 1], dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "loss = criterion(y_pred, y_true)\n",
    "loss.backward()  # 计算梯度\n",
    "optimizer.step()  # 更新参数\n",
    "print(loss)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T06:47:10.084267800Z",
     "start_time": "2024-01-15T06:47:09.660267600Z"
    }
   },
   "id": "6a9254a7487db132"
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## 7. 动态调整学习率\n",
    "PyTorch 提供了一些学习率调整策略，如学习率衰减、余弦退火等。可以使用 `torch.optim.lr_scheduler` 模块来实现。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "56533a2eea752cb4"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MirrichD\\Anaconda3\\envs\\torch\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import lr_scheduler\n",
    "\n",
    "# 创建学习率衰减策略\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "num_epochs = 1\n",
    "\n",
    "# 在训练循环中使用\n",
    "for epoch in range(num_epochs):\n",
    "    # 训练模型\n",
    "    # ...\n",
    "\n",
    "    # 更新学习率\n",
    "    scheduler.step()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T06:47:10.084267800Z",
     "start_time": "2024-01-15T06:47:09.677268100Z"
    }
   },
   "id": "e72b5ad4275a9132"
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## 8. 自定义优化器\n",
    "可以通过继承 `torch.optim.Optimizer` 类来创建自定义的优化器。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7f0b959e30cf8912"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "class CustomOptimizer(optim.Optimizer):\n",
    "    def __init__(self, params, lr=0.01):\n",
    "        defaults = dict(lr=lr)\n",
    "        super(CustomOptimizer, self).__init__(params, defaults)\n",
    "\n",
    "    def step(self, closure=None):\n",
    "        # 自定义的优化步骤\n",
    "        ..."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T06:47:10.084267800Z",
     "start_time": "2024-01-15T06:47:09.693267700Z"
    }
   },
   "id": "2ba264431f03043f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "优化器是深度学习训练过程中关键的组件之一，选择适当的优化器和学习率策略对于模型的性能至关重要。PyTorch 提供了丰富的优化器和学习率调整工具，使得用户能够根据具体问题选择合适的训练策略。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f3a23b9aa369b6bb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 损失函数（Loss Function）\n",
    "\n",
    "损失函数（Loss Function）用于度量模型输出与真实标签之间的差异，是训练神经网络时优化的目标。\n",
    "\n",
    "PyTorch 提供了多种损失函数，适用于不同类型的任务，如分类、回归等。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f9ce3ea49fe2e6db"
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## 1. 均方误差损失（Mean Squared Error, MSE）\n",
    "均方误差是回归任务中常用的损失函数，计算模型输出与真实标签之间的平方差的平均值。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c98364fce1b5424d"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "criterion = nn.MSELoss()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T06:47:10.084267800Z",
     "start_time": "2024-01-15T06:47:09.708353600Z"
    }
   },
   "id": "5274e07b987544b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## 2. 交叉熵损失（Cross-Entropy Loss）\n",
    "交叉熵损失是分类任务中常用的损失函数，适用于多类别分类问题。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "350c36b5dc377623"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T06:47:10.084267800Z",
     "start_time": "2024-01-15T06:47:09.725352Z"
    }
   },
   "id": "fd3032534aff1387"
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## 3. 二元交叉熵损失（Binary Cross-Entropy Loss）\n",
    "二元交叉熵损失通常用于二分类问题，其中每个样本属于两个类别之一。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f51f1cbb585b002b"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T06:47:10.084267800Z",
     "start_time": "2024-01-15T06:47:09.740357100Z"
    }
   },
   "id": "c9c3b8fc8367c669"
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## 4. 二元交叉熵损失（带权重）\n",
    "可以为每个类别设置不同的权重，以处理类别不平衡的问题。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "80446d43f165beb5"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "weight_class_0 = 0.7\n",
    "weight_class_1 = 0.3\n",
    "\n",
    "weights = torch.tensor([weight_class_0, weight_class_1])\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=weights)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T06:47:10.084267800Z",
     "start_time": "2024-01-15T06:47:09.757348800Z"
    }
   },
   "id": "4db1daf474d0415b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## 5. K-L 散度损失（Kullback-Leibler Divergence Loss）\n",
    "适用于度量两个概率分布之间的差异，通常用于生成对抗网络（GANs）。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bccbe34ecb13439f"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "criterion = nn.KLDivLoss()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T06:47:10.084267800Z",
     "start_time": "2024-01-15T06:47:09.772267500Z"
    }
   },
   "id": "288bf37adbe4a311"
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## 6. 三元组损失（Triplet Margin Loss）\n",
    "在训练人脸识别等任务时，可以使用三元组损失来确保相同类别样本之间的距离小于不同类别样本之间的距离。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "14bc4fd149ef8aa4"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "from torch.nn.functional import triplet_margin_loss\n",
    "\n",
    "criterion = triplet_margin_loss"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T06:47:10.084267800Z",
     "start_time": "2024-01-15T06:47:09.789267800Z"
    }
   },
   "id": "32386716613ad1e1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## 7. 自定义损失函数\n",
    "可以通过继承 `nn.Module` 类创建自定义的损失函数，实现自定义的损失计算逻辑。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f6be4e42ecc259c3"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "class CustomLoss(nn.Module):\n",
    "    def __init__(self, weight):\n",
    "        super(CustomLoss, self).__init__()\n",
    "        self.weight = weight\n",
    "\n",
    "    def forward(self, output, target):\n",
    "        loss = torch.mean((output - target) ** 2)\n",
    "        return self.weight * loss"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T06:47:10.084267800Z",
     "start_time": "2024-01-15T06:47:09.804278600Z"
    }
   },
   "id": "6630462d3b6b3655"
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## 8. 使用损失函数进行训练\n",
    "在训练循环中，通过计算模型输出与真实标签的损失，并调用反向传播和优化器更新参数来训练模型。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1e8a82a3468a4e48"
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "# 定义一个简单案例\n",
    "inputs = torch.randn(10)\n",
    "labels = torch.randn(5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "output = model(inputs)\n",
    "loss = criterion(output, labels)\n",
    "\n",
    "optimizer.zero_grad()\n",
    "loss.backward()\n",
    "optimizer.step()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T06:47:10.084267800Z",
     "start_time": "2024-01-15T06:47:09.819267400Z"
    }
   },
   "id": "e7bcc414f1cdcb4c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "选择适当的损失函数取决于任务类型和数据特性。通常，可以根据任务的性质和输出的特点选择合适的损失函数。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b47c78254f3a038e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 数据加载与预处理\n",
    "\n",
    "在 PyTorch 中，数据加载与预处理是深度学习中非常重要的一部分，它涉及到将原始数据加载到模型中并进行适当的预处理，以便用于训练和测试。PyTorch 提供了 `torch.utils.data` 模块来实现数据加载和预处理，同时可以使用 `torchvision` 提供的一些工具进行常见的图像处理。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "474b56b7fcb53c6a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## 1. 数据集的定义\n",
    "在 PyTorch 中，通常通过创建一个自定义的数据集类来加载数据。自定义数据集需要继承自 `torch.utils.data.Dataset`，并实现 `__len__` 和 `__getitem__` 方法。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2f17c9801b29c2cd"
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, labels, transform=None):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = {'data': self.data[idx], 'label': self.labels[idx]}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T06:47:10.084267800Z",
     "start_time": "2024-01-15T06:47:09.836268100Z"
    }
   },
   "id": "ff590cde3e103d79"
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## 2. 数据加载器\n",
    "数据加载器是 PyTorch 中用于批量加载数据的工具。通过创建一个数据加载器，可以方便地在模型训练中迭代地获取批量数据。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6925f703e1cb33eb"
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 创建一个 MNIST 格式的简单数据案例\n",
    "data = torch.randn(50000, 28, 28)\n",
    "labels = torch.randint(0, 9, (50000,))\n",
    "\n",
    "# 创建数据集\n",
    "dataset = CustomDataset(data, labels, transform=None)\n",
    "\n",
    "# 创建数据加载器\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T06:47:10.112352Z",
     "start_time": "2024-01-15T06:47:09.851267600Z"
    }
   },
   "id": "c412058c5f09142c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## 3. 预处理与转换\n",
    "可以使用 `torchvision.transforms` 中的预处理函数对数据进行常见的预处理，例如缩放、裁剪、旋转等。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a878400e829b0e22"
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "# 定义转换\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.RandomCrop((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "# 将转换应用于数据集\n",
    "dataset = CustomDataset(data, labels, transform=transform)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T06:47:10.774791100Z",
     "start_time": "2024-01-15T06:47:10.005267300Z"
    }
   },
   "id": "b6908b8349dde0df"
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## 4. 使用预训练模型\n",
    "如果使用了预训练的模型，可能需要采用与训练时相同的预处理方式。`torchvision.transforms` 中也提供了用于预训练模型的一些标准预处理方法。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "75fdf55a6ea6fb4"
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "# 使用 ImageNet 预训练模型的标准化参数\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T06:47:10.824869Z",
     "start_time": "2024-01-15T06:47:10.258267200Z"
    }
   },
   "id": "56784f16baab2008"
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## 5. 数据加载与迭代\n",
    "通过数据加载器，可以在训练循环中方便地迭代加载批量的数据。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b7c758bde6318f6a"
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 28, 28]) torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "for batch in dataloader:\n",
    "    inputs, labels = batch['data'], batch['label']\n",
    "    print(inputs.shape, labels.shape)\n",
    "    break\n",
    "    # 进行模型训练"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T06:47:10.853869Z",
     "start_time": "2024-01-15T06:47:10.274545800Z"
    }
   },
   "id": "c61522225b581cbb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "这些步骤提供了一个基本的数据加载与预处理的框架。根据实际问题和数据特点，可能需要进行更复杂的数据处理。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "83a3c457afa9f5ef"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 模型保存与加载\n",
    "在 PyTorch 中，模型的保存与加载是训练深度学习模型中重要的一部分。模型的保存使得可以在训练过程中保存中间结果或在训练结束后保存最终模型，而模型的加载则允许在其他地方或其他时间使用已经训练好的模型。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "677b43614f594f2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## 1. 模型的保存\n",
    "在 PyTorch 中，可以使用 `torch.save` 函数保存模型的状态字典（state_dict）或整个模型。状态字典包含了模型的参数和其他相关信息。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4dceed7db5911a20"
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 定义模型\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.fc = nn.Linear(10, 1)\n",
    "\n",
    "model = SimpleModel()\n",
    "\n",
    "# 保存模型的状态字典\n",
    "torch.save(model.state_dict(), 'model_state.pth')\n",
    "\n",
    "# 保存整个模型（包括结构和参数）\n",
    "torch.save(model, 'model.pth')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T06:47:10.854873200Z",
     "start_time": "2024-01-15T06:47:10.289510600Z"
    }
   },
   "id": "47079dc9b887de03"
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## 2. 模型的加载\n",
    "使用 `torch.load` 函数加载模型的状态字典或整个模型。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "af9da000d2952da0"
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "# 加载模型的状态字典\n",
    "loaded_state_dict = torch.load('model_state.pth')\n",
    "model.load_state_dict(loaded_state_dict)\n",
    "\n",
    "# 加载整个模型\n",
    "loaded_model = torch.load('model.pth')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T06:47:10.854873200Z",
     "start_time": "2024-01-15T06:47:10.308524400Z"
    }
   },
   "id": "838b1b9c94178946"
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## 3. 跨设备加载模型\n",
    "如果在训练时使用了 GPU，而在加载时想切换到 CPU，可以使用 `map_location` 参数。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4af84ba1fd885134"
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "# 在 CPU 上加载 GPU 上保存的模型\n",
    "loaded_model = torch.load('model.pth', map_location=torch.device('cpu'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T06:47:10.854873200Z",
     "start_time": "2024-01-15T06:47:10.336605400Z"
    }
   },
   "id": "80578344681a74ef"
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## 4. 保存与加载模型的结构和参数\n",
    "在保存整个模型时，模型的结构和参数都会被保存。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "736525dd3f080aaa"
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "# 保存整个模型（包括结构和参数）\n",
    "torch.save(model, 'model.pth')\n",
    "\n",
    "# 加载整个模型\n",
    "loaded_model = torch.load('model.pth')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T06:47:10.854873200Z",
     "start_time": "2024-01-15T06:47:10.352567900Z"
    }
   },
   "id": "3db96cd9dd9f28c1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## 5. 保存与加载模型的结构\n",
    "**注：此为老版本功能，部分电脑运行可能会错误**\n",
    "\n",
    "如果只想保存和加载模型的结构而不包含参数，可以使用 `torch.save` 时设置 `save_model_obj=False`。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fb02649f9f26785b"
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "# # 保存模型结构\n",
    "# torch.save(model, 'model_structure.pth', save_model_obj=False)\n",
    "# \n",
    "# # 加载模型结构\n",
    "# loaded_model_structure = torch.load('model_structure.pth')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T06:47:10.854873200Z",
     "start_time": "2024-01-15T06:47:10.367524100Z"
    }
   },
   "id": "c30b4afe396432c9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## 6. 只保存和加载模型参数\n",
    "如果只想保存和加载模型参数而不包含模型结构，可以使用 `torch.save` 时只保存模型的 `.state_dict()`。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ecbd27893190b8a6"
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 保存模型参数\n",
    "torch.save(model.state_dict(), 'model_parameters.pth')\n",
    "\n",
    "# 加载模型参数\n",
    "loaded_parameters = torch.load('model_parameters.pth')\n",
    "model.load_state_dict(loaded_parameters)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T06:47:10.855825800Z",
     "start_time": "2024-01-15T06:47:10.382524600Z"
    }
   },
   "id": "c03072f7fd9158de"
  },
  {
   "cell_type": "markdown",
   "source": [
    "以上是在 PyTorch 中保存与加载模型的基本方法。在实际应用中，还可以结合其他工具，如 `torch.optim` 优化器状态字典的保存与加载，以便在恢复训练时继续优化过程。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4a9114d032d5dc25"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 学习率调整\n",
    "\n",
    "在深度学习中，学习率调整是优化算法的关键部分之一。PyTorch 提供了 `torch.optim.lr_scheduler` 模块来实现各种学习率调整策略。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "70ce42c3c3f5e34a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## 1. StepLR 学习率调整\n",
    "StepLR 是一种简单的学习率调整策略，每经过一定的步数，将学习率按照给定的因子进行衰减。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7662747508bf78cd"
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MirrichD\\Anaconda3\\envs\\torch\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "# 定义优化器\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# 定义学习率调整策略\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "# 在训练循环中使用\n",
    "for epoch in range(num_epochs):\n",
    "    # 训练模型\n",
    "    # ...\n",
    "\n",
    "    # 更新学习率\n",
    "    scheduler.step()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T06:47:10.857870Z",
     "start_time": "2024-01-15T06:47:10.398605200Z"
    }
   },
   "id": "4cbea3cfbd8bcf05"
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## 2. MultiStepLR 学习率调整\n",
    "MultiStepLR 是在预定义的多个时间点降低学习率的策略。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2862fc7eae154c5b"
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "scheduler = lr_scheduler.MultiStepLR(optimizer, milestones=[10, 20, 30], gamma=0.1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T06:47:10.858791Z",
     "start_time": "2024-01-15T06:47:10.412523900Z"
    }
   },
   "id": "552d2edcc23d09ef"
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## 3. ExponentialLR 学习率调整\n",
    "ExponentialLR 对学习率进行指数衰减。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2166faaa5392dc4b"
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=0.9)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T06:47:10.858791Z",
     "start_time": "2024-01-15T06:47:10.429524400Z"
    }
   },
   "id": "ad419628d3adb64b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## 4. CosineAnnealingLR 学习率调整\n",
    "CosineAnnealingLR 使用余弦退火函数来调整学习率。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "58532e78190879ef"
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T06:47:10.858791Z",
     "start_time": "2024-01-15T06:47:10.444780900Z"
    }
   },
   "id": "38f975a63485397c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## 5. LambdaLR 学习率调整\n",
    "LambdaLR 允许使用任意的学习率调整函数。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fa00709e6f8c1b32"
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda epoch: 0.95 ** epoch)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T06:47:10.888899900Z",
     "start_time": "2024-01-15T06:47:10.460312500Z"
    }
   },
   "id": "95531f4a5439d13d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## 6. ReduceLROnPlateau 学习率调整\n",
    "ReduceLROnPlateau 在验证集上监测指标，当指标不再提升时降低学习率。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4040284ee4413564"
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T06:47:10.889790600Z",
     "start_time": "2024-01-15T06:47:10.476463400Z"
    }
   },
   "id": "fef373284e5c4afa"
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## 7. 使用学习率调整器\n",
    "在训练循环中使用学习率调整器。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "646e22bf8014e20f"
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    # 训练模型\n",
    "    # ...\n",
    "    # 简单随机创建一个验证损失\n",
    "    validation_loss = torch.randn(1)\n",
    "\n",
    "    # 更新学习率\n",
    "    scheduler.step(validation_loss)  # 如果使用 ReduceLROnPlateau"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T06:47:10.890790200Z",
     "start_time": "2024-01-15T06:47:10.491790600Z"
    }
   },
   "id": "fefad003be486de0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## 8. 学习率调整的参数\n",
    "在学习率调整中，有一些参数是常用的：\n",
    "- optimizer: 优化器，可以通过 optim.SGD、optim.Adam 等创建。\n",
    "- step_size（对于 StepLR 和 MultiStepLR）: 学习率衰减的步数。\n",
    "- gamma: 学习率衰减的因子。\n",
    "- milestones（对于 MultiStepLR）: 多步学习率衰减的时间点。\n",
    "- T_max（对于 CosineAnnealingLR）: 一个周期的迭代次数。\n",
    "- lr_lambda（对于 LambdaLR）: 自定义学习率衰减函数。\n",
    "- mode（对于 ReduceLROnPlateau）: 监测指标的模式，可以是 'min'、'max' 或 'auto'。\n",
    "\n",
    "选择适当的学习率调整策略对于模型的性能非常关键。在实践中，通常需要进行一些实验以确定最佳的学习率调整策略和参数。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ff5d8b6f5dbca9f8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 模型评估\n",
    "模型评估是在训练之后对模型性能进行定量评估的过程。评估模型涉及到使用验证集或测试集上的数据进行推理，并计算模型在这些数据上的性能指标，如准确率、精确度、召回率等。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a8e00264717455be"
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## 1. 设置模型为评估模式\n",
    "在进行模型评估之前，需要将模型切换到评估模式，即使用 `eval()` 方法。这会关闭 Dropout 等训练时使用的一些特定行为。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6642db44a6e37baa"
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "data": {
      "text/plain": "SimpleModel(\n  (fc): Linear(in_features=10, out_features=1, bias=True)\n)"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T06:47:10.891890500Z",
     "start_time": "2024-01-15T06:47:10.506790600Z"
    }
   },
   "id": "5d891557e5a3dd4d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## 2. 使用验证集或测试集进行推理\n",
    "通过遍历验证集或测试集，使用模型进行推理。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e27f2c73165f1632"
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "# 创建一个 适用于 MNIST 格式的神经网络\n",
    "class MNISTModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MNISTModel, self).__init__()\n",
    "        self.fc = nn.Linear(28*28, 10)\n",
    "    def forward(self, inputs):\n",
    "        x = inputs.flatten(1)\n",
    "        outputs = self.fc(x)\n",
    "        \n",
    "        return outputs\n",
    "\n",
    "model = MNISTModel()\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in dataloader:\n",
    "        inputs, labels = batch[\"data\"], batch[\"label\"]\n",
    "        outputs = model(inputs)\n",
    "        break\n",
    "        # 进行后续处理..."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T06:47:10.891890500Z",
     "start_time": "2024-01-15T06:47:10.524791Z"
    }
   },
   "id": "f1d8dd5405d51968"
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## 3. 计算性能指标\n",
    "根据任务类型和需求，选择合适的性能指标进行计算。以下是一些常见的性能指标：\n",
    "\n",
    "- 准确率（Accuracy）：\n",
    "```python\n",
    "correct = (predicted == labels).sum().item()\n",
    "total = labels.size(0)\n",
    "accuracy = correct / total\n",
    "```\n",
    "\n",
    "- 精确度（Precision）：\n",
    "```python\n",
    "from sklearn.metrics import precision_score\n",
    "precision = precision_score(labels, predicted, average='weighted')\n",
    "```\n",
    "- 召回率（Recall）：\n",
    "```python\n",
    "from sklearn.metrics import recall_score\n",
    "recall = recall_score(labels, predicted, average='weighted')\n",
    "```\n",
    "\n",
    "- F1 分数（F1 Score）：\n",
    "```python\n",
    "from sklearn.metrics import f1_score\n",
    "f1 = f1_score(labels, predicted, average='weighted')\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "43c16021d11dbdd1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## 4. 混淆矩阵（Confusion Matrix）\n",
    "混淆矩阵是一个很有用的工具，可以展示模型在每个类别上的性能。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1e1165fbd44b858f"
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 1 0 0 0]\n",
      " [0 0 0 1 0 0 0 1]\n",
      " [0 0 0 0 0 1 0 0]\n",
      " [0 0 2 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 1 0 0 0]\n",
      " [0 0 0 1 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# 创建一个简单的目标类别和预测类别\n",
    "labels = torch.randint(0, 9, (10,))\n",
    "predicted = torch.randint(0, 9, (10,))\n",
    "\n",
    "conf_matrix = confusion_matrix(labels, predicted)\n",
    "print(conf_matrix)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T06:47:11.319791Z",
     "start_time": "2024-01-15T06:47:10.555790800Z"
    }
   },
   "id": "dd0990134eaa7e78"
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## 5. 模型性能可视化\n",
    "通过绘制 ROC 曲线、学习曲线等图表，可以更直观地了解模型的性能。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "80ee87be4fec7e97"
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 绘制 ROC 曲线等"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T06:47:11.322790700Z",
     "start_time": "2024-01-15T06:47:10.955869700Z"
    }
   },
   "id": "9232adf60d501893"
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## 6. 完整的评估过程示例"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e9f7c2b24ef344f9"
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0999\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "total_correct = 0\n",
    "total_samples = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in dataloader:\n",
    "        inputs = batch[\"data\"]\n",
    "        labels = batch[\"label\"]\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        \n",
    "        total_correct += (predicted == labels).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "\n",
    "accuracy = total_correct / total_samples\n",
    "print(f'Accuracy: {accuracy}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T06:47:11.737001400Z",
     "start_time": "2024-01-15T06:47:11.272872100Z"
    }
   },
   "id": "12f6c2b932ad399d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## 7. 注意事项\n",
    "- 在评估过程中，确保使用 `torch.no_grad()` 来关闭梯度计算，以减少内存使用和加速推理过程。\n",
    "- 对于分类问题，使用 Softmax 函数获得类别概率，并选择概率最大的类别作为预测结果。\n",
    "- 对于不同的任务（分类、回归、目标检测等），选择合适的性能指标进行评估。\n",
    "\n",
    "以上是在 PyTorch 中进行模型评估的基本步骤。具体的评估过程会根据任务的性质和需求而有所不同。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "de083860177387b8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# GPU 加速\n",
    "\n",
    "在 PyTorch 中，利用 GPU 加速是训练深度学习模型的关键步骤之一。PyTorch 提供了简单而灵活的方式，使用户能够方便地将模型和数据移动到 GPU 上进行加速。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "915bc5800597c92"
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## 1. 检查 GPU 是否可用\n",
    "在使用 GPU 加速之前，首先需要检查系统上是否有可用的 GPU 设备。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "88062b12f984cfe2"
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 检查 GPU 是否可用\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T06:47:11.737001400Z",
     "start_time": "2024-01-15T06:47:11.714946200Z"
    }
   },
   "id": "9c741d6c86ebf217"
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## 2. 将模型移动到 GPU\n",
    "使用 `.to()` 方法将模型移动到 GPU 上。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6446e6d3cf805ce9"
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "data": {
      "text/plain": "MNISTModel(\n  (fc): Linear(in_features=784, out_features=10, bias=True)\n)"
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MNISTModel()  # 自定义模型\n",
    "model.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T06:47:11.867997500Z",
     "start_time": "2024-01-15T06:47:11.730005700Z"
    }
   },
   "id": "7a7b9e4bfe130a01"
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## 3. 将张量移动到 GPU\n",
    "同样地，使用 `.to()` 方法将张量移动到 GPU 上。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "61530a5f59b4dbe6"
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "inputs, labels = batch[\"data\"], batch[\"label\"]  # 假设 data 是从数据加载器中获取的一批数据\n",
    "inputs, labels = inputs.to(device), labels.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T06:47:11.908005400Z",
     "start_time": "2024-01-15T06:47:11.747009500Z"
    }
   },
   "id": "b315ce1527f1d2dc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## 4. 在 GPU 上执行前向传播和反向传播\n",
    "使用 GPU 上的模型进行前向传播和反向传播。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2285d164409b1ef5"
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "outputs = model(inputs)\n",
    "loss = criterion(outputs, labels)\n",
    "\n",
    "optimizer.zero_grad()\n",
    "loss.backward()\n",
    "optimizer.step()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T06:47:13.735698Z",
     "start_time": "2024-01-15T06:47:11.761959100Z"
    }
   },
   "id": "ff2d6ae653582d49"
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## 5. 多 GPU 加速\n",
    "PyTorch 支持多 GPU 加速，可以使用 `torch.nn.DataParallel` 封装模型，使其能够并行在多个 GPU 上执行。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fa47896cd27a9027"
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "data": {
      "text/plain": "DataParallel(\n  (module): MNISTModel(\n    (fc): Linear(in_features=784, out_features=10, bias=True)\n  )\n)"
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MNISTModel()\n",
    "model = nn.DataParallel(model)\n",
    "model.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T06:47:13.763712600Z",
     "start_time": "2024-01-15T06:47:13.732703800Z"
    }
   },
   "id": "e623605ca5e17fcd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## 6. 在 GPU 上保存和加载模型\n",
    "保存和加载模型时，可以选择将模型参数保存到或加载自 GPU。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3b360df0512ddf75"
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "data": {
      "text/plain": "DataParallel(\n  (module): MNISTModel(\n    (fc): Linear(in_features=784, out_features=10, bias=True)\n  )\n)"
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 保存模型到 GPU\n",
    "torch.save(model.state_dict(), 'model.pth')\n",
    "\n",
    "# 加载模型到 GPU\n",
    "model.load_state_dict(torch.load('model.pth'))\n",
    "model.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T06:47:13.808695700Z",
     "start_time": "2024-01-15T06:47:13.749710300Z"
    }
   },
   "id": "c5c580b96af938f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## 7. GPU 上的数据并行\n",
    "**注：请确保单机多卡或者多机多卡相同的环境下才可使用，否则可能出现错误！**\n",
    "在使用多 GPU 进行数据并行训练时，可以使用 `torch.nn.parallel.DistributedDataParallel`。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "454fb5441d6dfab2"
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Default process group has not been initialized, please make sure to call init_process_group.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[64], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m model \u001B[38;5;241m=\u001B[39m MNISTModel()\n\u001B[1;32m----> 2\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mnn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparallel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mDistributedDataParallel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      3\u001B[0m model\u001B[38;5;241m.\u001B[39mto(device)\n",
      "File \u001B[1;32m~\\Anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\parallel\\distributed.py:595\u001B[0m, in \u001B[0;36mDistributedDataParallel.__init__\u001B[1;34m(self, module, device_ids, output_device, dim, broadcast_buffers, process_group, bucket_cap_mb, find_unused_parameters, check_reduction, gradient_as_bucket_view, static_graph)\u001B[0m\n\u001B[0;32m    592\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutput_device \u001B[38;5;241m=\u001B[39m _get_device_index(output_device, \u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m    594\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m process_group \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 595\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocess_group \u001B[38;5;241m=\u001B[39m \u001B[43m_get_default_group\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    596\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    597\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocess_group \u001B[38;5;241m=\u001B[39m process_group\n",
      "File \u001B[1;32m~\\Anaconda3\\envs\\torch\\lib\\site-packages\\torch\\distributed\\distributed_c10d.py:429\u001B[0m, in \u001B[0;36m_get_default_group\u001B[1;34m()\u001B[0m\n\u001B[0;32m    425\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    426\u001B[0m \u001B[38;5;124;03mGetting the default process group created by init_process_group\u001B[39;00m\n\u001B[0;32m    427\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    428\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_initialized():\n\u001B[1;32m--> 429\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[0;32m    430\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDefault process group has not been initialized, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    431\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mplease make sure to call init_process_group.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    432\u001B[0m     )\n\u001B[0;32m    433\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m GroupMember\u001B[38;5;241m.\u001B[39mWORLD\n",
      "\u001B[1;31mRuntimeError\u001B[0m: Default process group has not been initialized, please make sure to call init_process_group."
     ]
    }
   ],
   "source": [
    "model = MNISTModel()\n",
    "model = nn.parallel.DistributedDataParallel(model)\n",
    "model.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T06:47:14.225993100Z",
     "start_time": "2024-01-15T06:47:13.764702900Z"
    }
   },
   "id": "c8234ea15cc87e7c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
